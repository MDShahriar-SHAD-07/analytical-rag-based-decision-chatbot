{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñ Restaurant Intelligence Chatbot - Production System\n",
    "\n",
    "**Enterprise-Grade Conversational AI with RAG**\n",
    "\n",
    "This system integrates:\n",
    "- ‚úÖ Advanced Sentiment Analysis\n",
    "- ‚úÖ Independent Aspect-Based Analysis\n",
    "- ‚úÖ Vector Retrieval (RAG)\n",
    "- ‚úÖ LLM-Driven Recommendations\n",
    "- ‚úÖ Hallucination Prevention\n",
    "- ‚úÖ Production-Grade Error Handling\n",
    "\n",
    "---\n",
    "\n",
    "## System Architecture\n",
    "\n",
    "```\n",
    "User Query ‚Üí Intent Router ‚Üí Vector Retrieval ‚Üí LLM Reasoning ‚Üí Structured Response\n",
    "                ‚Üì                    ‚Üì                ‚Üì\n",
    "         Context Memory      Semantic Search    Grounded Generation\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T15:58:24.915415Z",
     "iopub.status.busy": "2026-02-15T15:58:24.914892Z",
     "iopub.status.idle": "2026-02-15T15:58:41.583722Z",
     "shell.execute_reply": "2026-02-15T15:58:41.583009Z",
     "shell.execute_reply.started": "2026-02-15T15:58:24.915385Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.4/21.4 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m95.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m220.0/220.0 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m108.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-adk 1.22.1 requires google-cloud-bigquery-storage>=2.0.0, which is not installed.\n",
      "bigframes 2.26.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "google-adk 1.22.1 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.39.1 which is incompatible.\n",
      "google-adk 1.22.1 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
      "opentelemetry-exporter-gcp-logging 1.11.0a0 requires opentelemetry-sdk<1.39.0,>=1.35.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
      "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.47.0 which is incompatible.\n",
      "google-colab 1.0.0 requires jupyter-server==2.14.0, but you have jupyter-server 2.12.5 which is incompatible.\n",
      "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
      "cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
      "gradio 5.49.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.5 which is incompatible.\n",
      "bigframes 2.26.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\n",
      "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.39.1 which is incompatible.\n",
      "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.39.1 which is incompatible.\n",
      "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
      "fastai 2.8.4 requires fastcore<1.9,>=1.8.0, but you have fastcore 1.11.3 which is incompatible.\n",
      "pylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q \\\n",
    "    chromadb \\\n",
    "    langchain \\\n",
    "    langchain-community \\\n",
    "    sentence-transformers \\\n",
    "    transformers \\\n",
    "    accelerate \\\n",
    "    python-dotenv\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Installation & Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Configuration & Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T15:58:48.205770Z",
     "iopub.status.busy": "2026-02-15T15:58:48.205022Z",
     "iopub.status.idle": "2026-02-15T15:59:26.453278Z",
     "shell.execute_reply": "2026-02-15T15:59:26.452526Z",
     "shell.execute_reply.started": "2026-02-15T15:58:48.205734Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-15 15:59:00.048478: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1771171140.275139      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1771171140.340010      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1771171140.873177      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1771171140.873230      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1771171140.873233      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1771171140.873235      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All dependencies loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Core Imports\n",
    "import os\n",
    "import warnings\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple, Any\n",
    "from dataclasses import dataclass, field\n",
    "import json\n",
    "\n",
    "# Data Processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ML & NLP\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Vector DB & RAG\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.schema import Document\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.llms.base import LLM\n",
    "\n",
    "# Validation\n",
    "from pydantic import BaseModel, Field, validator\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "tqdm.pandas()\n",
    "\n",
    "print(\"‚úÖ All dependencies loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T16:00:18.556932Z",
     "iopub.status.busy": "2026-02-15T16:00:18.556075Z",
     "iopub.status.idle": "2026-02-15T16:00:18.565534Z",
     "shell.execute_reply": "2026-02-15T16:00:18.564880Z",
     "shell.execute_reply.started": "2026-02-15T16:00:18.556903Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Configuration loaded - Device: cuda\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class SystemConfig:\n",
    "    \"\"\"Production-grade configuration with environment variable support\"\"\"\n",
    "    \n",
    "    # Paths\n",
    "    data_path: str = \"/kaggle/input/datasets/shahriard07/restaurant-review/dhaka_restaurants.csv\"\n",
    "    vector_db_path: str = \"/kaggle/working/restaurant_vector_db\"\n",
    "    \n",
    "    # Model Configuration\n",
    "    sentiment_model: str = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "    embedding_model: str = \"all-MiniLM-L6-v2\"\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    # LLM Configuration\n",
    "    llm_temperature: float = 0.2\n",
    "    max_tokens: int = 512\n",
    "    \n",
    "    # RAG Configuration\n",
    "    retrieval_k: int = 5\n",
    "    similarity_threshold: float = 0.7\n",
    "    \n",
    "    # Aspect Keywords\n",
    "    aspects: Dict[str, List[str]] = field(default_factory=lambda: {\n",
    "        \"food\": [\"food\", \"taste\", \"meal\", \"dish\", \"cuisine\", \"flavor\", \"delicious\", \"‡¶ñ‡¶æ‡¶¨‡¶æ‡¶∞\", \"‡¶∏‡ßç‡¶¨‡¶æ‡¶¶\"],\n",
    "        \"service\": [\"service\", \"staff\", \"waiter\", \"waitress\", \"manager\", \"server\", \"‡¶∏‡¶æ‡¶∞‡ßç‡¶≠‡¶ø‡¶∏\", \"‡¶ï‡¶∞‡ßç‡¶Æ‡ßÄ\"],\n",
    "        \"price\": [\"price\", \"cost\", \"expensive\", \"cheap\", \"value\", \"affordable\", \"‡¶¶‡¶æ‡¶Æ\", \"‡¶Æ‡ßÇ‡¶≤‡ßç‡¶Ø\"],\n",
    "        \"ambience\": [\"ambience\", \"atmosphere\", \"environment\", \"decor\", \"vibe\", \"‡¶™‡¶∞‡¶ø‡¶¨‡ßá‡¶∂\"],\n",
    "        \"cleanliness\": [\"clean\", \"hygiene\", \"sanitary\", \"dirty\", \"‡¶™‡¶∞‡¶ø‡¶∑‡ßç‡¶ï‡¶æ‡¶∞\"]\n",
    "    })\n",
    "    \n",
    "    # Negative Triggers\n",
    "    negative_triggers: List[str] = field(default_factory=lambda: [\n",
    "        \"late\", \"slow\", \"rude\", \"bad\", \"cold\", \"delay\", \"terrible\", \"awful\",\n",
    "        \"disappointing\", \"poor\", \"worst\", \"‡¶ñ‡¶æ‡¶∞‡¶æ‡¶™\", \"‡¶¶‡ßá‡¶∞‡¶ø\", \"‡¶†‡¶æ‡¶®‡ßç‡¶°‡¶æ\"\n",
    "    ])\n",
    "    \n",
    "    # Production Settings\n",
    "    batch_size: int = 32\n",
    "    enable_logging: bool = True\n",
    "    fallback_enabled: bool = True\n",
    "\n",
    "# Initialize configuration\n",
    "config = SystemConfig()\n",
    "logger.info(f\"System initialized on device: {config.device}\")\n",
    "print(f\"üîß Configuration loaded - Device: {config.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Data Layer - Schema Validation & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T16:00:22.737683Z",
     "iopub.status.busy": "2026-02-15T16:00:22.737380Z",
     "iopub.status.idle": "2026-02-15T16:00:22.858838Z",
     "shell.execute_reply": "2026-02-15T16:00:22.858196Z",
     "shell.execute_reply.started": "2026-02-15T16:00:22.737657Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Data Summary:\n",
      "Total Reviews: 977\n",
      "Unique Restaurants: 126\n",
      "Average Review Length: 405 chars\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_name</th>\n",
       "      <th>business_address</th>\n",
       "      <th>business_phone</th>\n",
       "      <th>business_website</th>\n",
       "      <th>business_rating</th>\n",
       "      <th>business_total_reviews</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_additional_info</th>\n",
       "      <th>business_name_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Izumi Japanese Kitchen</td>\n",
       "      <td>House 24 C, Rd 119, Dhaka 1212, Bangladesh</td>\n",
       "      <td>+880 1933-446677</td>\n",
       "      <td>https://m.facebook.com/izumiBD/</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2233</td>\n",
       "      <td>{'name': 'Raunak Maskay', 'thumbnail': 'https:...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>a month ago</td>\n",
       "      <td>Izumi Japanese Kitchen in Gulshan, Dhaka is on...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>izumi japanese kitchen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Izumi Japanese Kitchen</td>\n",
       "      <td>House 24 C, Rd 119, Dhaka 1212, Bangladesh</td>\n",
       "      <td>+880 1933-446677</td>\n",
       "      <td>https://m.facebook.com/izumiBD/</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2233</td>\n",
       "      <td>{'name': 'Dewan Asif', 'thumbnail': 'https://l...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4 months ago</td>\n",
       "      <td>Izumi Japanese Kitchen is a great place for re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>izumi japanese kitchen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Izumi Japanese Kitchen</td>\n",
       "      <td>House 24 C, Rd 119, Dhaka 1212, Bangladesh</td>\n",
       "      <td>+880 1933-446677</td>\n",
       "      <td>https://m.facebook.com/izumiBD/</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2233</td>\n",
       "      <td>{'name': 'Dr. Mehruba Mona', 'thumbnail': 'htt...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Edited 8 months ago</td>\n",
       "      <td>One of the authentic Japanese restaurant in Dh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>izumi japanese kitchen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            business_name                            business_address  \\\n",
       "0  Izumi Japanese Kitchen  House 24 C, Rd 119, Dhaka 1212, Bangladesh   \n",
       "1  Izumi Japanese Kitchen  House 24 C, Rd 119, Dhaka 1212, Bangladesh   \n",
       "2  Izumi Japanese Kitchen  House 24 C, Rd 119, Dhaka 1212, Bangladesh   \n",
       "\n",
       "     business_phone                 business_website  business_rating  \\\n",
       "0  +880 1933-446677  https://m.facebook.com/izumiBD/              4.5   \n",
       "1  +880 1933-446677  https://m.facebook.com/izumiBD/              4.5   \n",
       "2  +880 1933-446677  https://m.facebook.com/izumiBD/              4.5   \n",
       "\n",
       "   business_total_reviews                                      reviewer_name  \\\n",
       "0                    2233  {'name': 'Raunak Maskay', 'thumbnail': 'https:...   \n",
       "1                    2233  {'name': 'Dewan Asif', 'thumbnail': 'https://l...   \n",
       "2                    2233  {'name': 'Dr. Mehruba Mona', 'thumbnail': 'htt...   \n",
       "\n",
       "   review_rating          review_date  \\\n",
       "0            5.0          a month ago   \n",
       "1            5.0         4 months ago   \n",
       "2            5.0  Edited 8 months ago   \n",
       "\n",
       "                                         review_text  review_additional_info  \\\n",
       "0  Izumi Japanese Kitchen in Gulshan, Dhaka is on...                     NaN   \n",
       "1  Izumi Japanese Kitchen is a great place for re...                     NaN   \n",
       "2  One of the authentic Japanese restaurant in Dh...                     NaN   \n",
       "\n",
       "  business_name_normalized  \n",
       "0   izumi japanese kitchen  \n",
       "1   izumi japanese kitchen  \n",
       "2   izumi japanese kitchen  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ReviewSchema(BaseModel):\n",
    "    \"\"\"Pydantic schema for review validation\"\"\"\n",
    "    business_name: str = Field(..., min_length=1)\n",
    "    review_text: str = Field(..., min_length=10)\n",
    "    review_rating: float = Field(..., ge=1.0, le=5.0)\n",
    "    business_address: Optional[str] = None\n",
    "    \n",
    "    @validator('review_text')\n",
    "    def validate_text(cls, v):\n",
    "        if not isinstance(v, str) or len(v.strip()) < 10:\n",
    "            raise ValueError('Review text must be at least 10 characters')\n",
    "        return v.strip()\n",
    "\n",
    "class DataPipeline:\n",
    "    \"\"\"Production-grade data processing pipeline\"\"\"\n",
    "    \n",
    "    def __init__(self, config: SystemConfig):\n",
    "        self.config = config\n",
    "        self.df_raw = None\n",
    "        self.df_cleaned = None\n",
    "        \n",
    "    def load_and_validate(self, path: str) -> pd.DataFrame:\n",
    "        \"\"\"Load data with schema validation\"\"\"\n",
    "        try:\n",
    "            logger.info(f\"Loading data from {path}\")\n",
    "            df = pd.read_csv(path)\n",
    "            self.df_raw = df.copy()\n",
    "            \n",
    "            # Validate required columns\n",
    "            required_cols = ['business_name', 'review_text', 'review_rating']\n",
    "            missing = set(required_cols) - set(df.columns)\n",
    "            if missing:\n",
    "                raise ValueError(f\"Missing required columns: {missing}\")\n",
    "            \n",
    "            logger.info(f\"‚úÖ Loaded {len(df)} rows\")\n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Data loading failed: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def clean_data(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Clean and normalize data\"\"\"\n",
    "        logger.info(\"Starting data cleaning pipeline\")\n",
    "        \n",
    "        # Drop nulls\n",
    "        df_clean = df.dropna(subset=['review_text', 'business_name']).copy()\n",
    "        logger.info(f\"Removed {len(df) - len(df_clean)} null rows\")\n",
    "        \n",
    "        # Ensure text is string\n",
    "        df_clean = df_clean[df_clean['review_text'].apply(lambda x: isinstance(x, str))]\n",
    "        \n",
    "        # Text normalization\n",
    "        df_clean['review_text'] = (\n",
    "            df_clean['review_text']\n",
    "            .str.strip()\n",
    "            .str.replace(r'\\s+', ' ', regex=True)\n",
    "        )\n",
    "        \n",
    "        # Filter short reviews\n",
    "        df_clean = df_clean[df_clean['review_text'].str.len() >= 10]\n",
    "        \n",
    "        # Normalize restaurant names\n",
    "        df_clean['business_name_normalized'] = (\n",
    "            df_clean['business_name']\n",
    "            .str.strip()\n",
    "            .str.lower()\n",
    "        )\n",
    "        \n",
    "        # Deduplicate\n",
    "        before_dedup = len(df_clean)\n",
    "        df_clean = df_clean.drop_duplicates(subset=['business_name', 'review_text'])\n",
    "        logger.info(f\"Removed {before_dedup - len(df_clean)} duplicate reviews\")\n",
    "        \n",
    "        self.df_cleaned = df_clean.reset_index(drop=True)\n",
    "        logger.info(f\"‚úÖ Cleaning complete - {len(self.df_cleaned)} clean rows\")\n",
    "        \n",
    "        return self.df_cleaned\n",
    "    \n",
    "    def get_restaurant_index(self) -> Dict[str, int]:\n",
    "        \"\"\"Create restaurant name index for fast lookup\"\"\"\n",
    "        if self.df_cleaned is None:\n",
    "            raise ValueError(\"Data not cleaned yet\")\n",
    "        \n",
    "        return (\n",
    "            self.df_cleaned\n",
    "            .groupby('business_name_normalized')\n",
    "            .size()\n",
    "            .to_dict()\n",
    "        )\n",
    "\n",
    "# Initialize and run data pipeline\n",
    "data_pipeline = DataPipeline(config)\n",
    "df = data_pipeline.load_and_validate(config.data_path)\n",
    "df_cleaned = data_pipeline.clean_data(df)\n",
    "\n",
    "print(f\"\\nüìä Data Summary:\")\n",
    "print(f\"Total Reviews: {len(df_cleaned):,}\")\n",
    "print(f\"Unique Restaurants: {df_cleaned['business_name'].nunique():,}\")\n",
    "print(f\"Average Review Length: {df_cleaned['review_text'].str.len().mean():.0f} chars\")\n",
    "df_cleaned.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé≠ Sentiment Engine - Advanced Analysis with Fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T16:00:28.582833Z",
     "iopub.status.busy": "2026-02-15T16:00:28.582523Z",
     "iopub.status.idle": "2026-02-15T16:00:49.088616Z",
     "shell.execute_reply": "2026-02-15T16:00:49.088079Z",
     "shell.execute_reply.started": "2026-02-15T16:00:28.582807Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "297bb9dee0cf4cb987183c04bece964a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/841 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e84e37b2a99740ef8da960c4b253587d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e84cac9c6e9848c3ab4deea0e2c51755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "138c640d93f0477da34639d39dffdeaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "545386ea837140fca33cd16018a2938a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Sentiment Analysis:   0%|          | 4/977 [00:00<02:09,  7.53it/s]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 977/977 [00:10<00:00, 96.86it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé≠ Sentiment Distribution:\n",
      "overall_sentiment\n",
      "positive    726\n",
      "negative    213\n",
      "neutral      38\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Average Confidence: 72.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class SentimentEngine:\n",
    "    \"\"\"Production sentiment analyzer with fallback mechanisms\"\"\"\n",
    "    \n",
    "    def __init__(self, config: SystemConfig):\n",
    "        self.config = config\n",
    "        self.model = None\n",
    "        self.fallback_mode = False\n",
    "        self._load_model()\n",
    "    \n",
    "    def _load_model(self):\n",
    "        \"\"\"Load sentiment model with retry logic\"\"\"\n",
    "        try:\n",
    "            logger.info(f\"Loading sentiment model: {self.config.sentiment_model}\")\n",
    "            self.model = pipeline(\n",
    "                \"sentiment-analysis\",\n",
    "                model=self.config.sentiment_model,\n",
    "                device=0 if self.config.device == \"cuda\" else -1\n",
    "            )\n",
    "            logger.info(\"‚úÖ Sentiment model loaded\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Model loading failed: {e}. Enabling fallback mode.\")\n",
    "            self.fallback_mode = True\n",
    "    \n",
    "    def _normalize_label(self, label: str) -> str:\n",
    "        \"\"\"Normalize sentiment labels to standard format\"\"\"\n",
    "        label_lower = label.lower()\n",
    "        if 'pos' in label_lower:\n",
    "            return 'positive'\n",
    "        elif 'neg' in label_lower:\n",
    "            return 'negative'\n",
    "        else:\n",
    "            return 'neutral'\n",
    "    \n",
    "    def _fallback_sentiment(self, text: str) -> Tuple[str, float]:\n",
    "        \"\"\"Rule-based fallback sentiment analysis\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        \n",
    "        positive_words = ['good', 'great', 'excellent', 'amazing', 'love', 'best', 'wonderful']\n",
    "        negative_words = ['bad', 'terrible', 'awful', 'worst', 'hate', 'poor', 'disappointing']\n",
    "        \n",
    "        pos_count = sum(1 for word in positive_words if word in text_lower)\n",
    "        neg_count = sum(1 for word in negative_words if word in text_lower)\n",
    "        \n",
    "        if pos_count > neg_count:\n",
    "            return 'positive', 0.6\n",
    "        elif neg_count > pos_count:\n",
    "            return 'negative', 0.6\n",
    "        else:\n",
    "            return 'neutral', 0.5\n",
    "    \n",
    "    def analyze(self, text: str) -> Tuple[str, float]:\n",
    "        \"\"\"Analyze sentiment with error handling\"\"\"\n",
    "        try:\n",
    "            if self.fallback_mode or self.model is None:\n",
    "                return self._fallback_sentiment(text)\n",
    "            \n",
    "            # Truncate to model limit\n",
    "            result = self.model(text[:512])[0]\n",
    "            label = self._normalize_label(result['label'])\n",
    "            confidence = result['score']\n",
    "            \n",
    "            return label, confidence\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Sentiment analysis failed for text, using fallback: {e}\")\n",
    "            return self._fallback_sentiment(text)\n",
    "    \n",
    "    def batch_analyze(self, texts: List[str]) -> pd.DataFrame:\n",
    "        \"\"\"Batch process with progress tracking\"\"\"\n",
    "        logger.info(f\"Analyzing {len(texts)} reviews\")\n",
    "        \n",
    "        results = []\n",
    "        for text in tqdm(texts, desc=\"Sentiment Analysis\"):\n",
    "            label, confidence = self.analyze(text)\n",
    "            results.append({'sentiment': label, 'confidence': confidence})\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "\n",
    "# Run sentiment analysis\n",
    "sentiment_engine = SentimentEngine(config)\n",
    "sentiment_results = sentiment_engine.batch_analyze(df_cleaned['review_text'].tolist())\n",
    "\n",
    "df_cleaned['overall_sentiment'] = sentiment_results['sentiment']\n",
    "df_cleaned['sentiment_confidence'] = sentiment_results['confidence']\n",
    "\n",
    "print(\"\\nüé≠ Sentiment Distribution:\")\n",
    "print(df_cleaned['overall_sentiment'].value_counts())\n",
    "print(f\"\\nAverage Confidence: {df_cleaned['sentiment_confidence'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Aspect Extraction - Independent Analysis (NOT Copied from Overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T16:01:08.644755Z",
     "iopub.status.busy": "2026-02-15T16:01:08.643986Z",
     "iopub.status.idle": "2026-02-15T16:01:26.402791Z",
     "shell.execute_reply": "2026-02-15T16:01:26.402089Z",
     "shell.execute_reply.started": "2026-02-15T16:01:08.644726Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aspect Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 977/977 [00:17<00:00, 55.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Aspect Analysis Summary:\n",
      "\n",
      "FOOD ‚Üí 837 mentions\n",
      "food_sentiment\n",
      "positive    595\n",
      "negative    177\n",
      "neutral      65\n",
      "Name: count, dtype: int64\n",
      "\n",
      "SERVICE ‚Üí 508 mentions\n",
      "service_sentiment\n",
      "positive    400\n",
      "negative     88\n",
      "neutral      20\n",
      "Name: count, dtype: int64\n",
      "\n",
      "PRICE ‚Üí 306 mentions\n",
      "price_sentiment\n",
      "positive    130\n",
      "negative    113\n",
      "neutral      63\n",
      "Name: count, dtype: int64\n",
      "\n",
      "AMBIENCE ‚Üí 388 mentions\n",
      "ambience_sentiment\n",
      "positive    328\n",
      "negative     41\n",
      "neutral      19\n",
      "Name: count, dtype: int64\n",
      "\n",
      "CLEANLINESS ‚Üí 74 mentions\n",
      "cleanliness_sentiment\n",
      "positive    55\n",
      "negative    13\n",
      "neutral      6\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# Aspect Extraction Module\n",
    "# ==============================\n",
    "\n",
    "class AspectAnalyzer:\n",
    "    \"\"\"Advanced aspect-based sentiment analyzer (Production Safe)\"\"\"\n",
    "\n",
    "    def __init__(self, config: SystemConfig, sentiment_engine: SentimentEngine):\n",
    "        self.config = config\n",
    "        self.sentiment_engine = sentiment_engine\n",
    "        self.aspects = config.aspects\n",
    "\n",
    "    def extract_aspect_text(self, text: str, aspect: str) -> Optional[str]:\n",
    "        if not isinstance(text, str) or not text.strip():\n",
    "            return None\n",
    "\n",
    "        text_lower = text.lower()\n",
    "        keywords = self.aspects.get(aspect, [])\n",
    "\n",
    "        # Aspect not mentioned at all\n",
    "        if not any(keyword in text_lower for keyword in keywords):\n",
    "            return None\n",
    "\n",
    "        # Extract relevant sentences\n",
    "        sentences = text.split(\".\")\n",
    "        relevant = []\n",
    "\n",
    "        for sentence in sentences:\n",
    "            if any(keyword in sentence.lower() for keyword in keywords):\n",
    "                relevant.append(sentence.strip())\n",
    "\n",
    "        return \" \".join(relevant) if relevant else text[:200]\n",
    "\n",
    "    def analyze_aspect(self, text: str, aspect: str) -> Dict[str, Any]:\n",
    "        aspect_text = self.extract_aspect_text(text, aspect)\n",
    "\n",
    "        if aspect_text is None:\n",
    "            return {\n",
    "                \"mentioned\": False,\n",
    "                \"sentiment\": None,\n",
    "                \"confidence\": 0.0\n",
    "            }\n",
    "\n",
    "        sentiment, confidence = self.sentiment_engine.analyze(aspect_text)\n",
    "\n",
    "        return {\n",
    "            \"mentioned\": True,\n",
    "            \"sentiment\": sentiment,\n",
    "            \"confidence\": confidence\n",
    "        }\n",
    "\n",
    "    def batch_analyze(self, texts: List[str]) -> pd.DataFrame:\n",
    "        results = []\n",
    "\n",
    "        for text in tqdm(texts, desc=\"Aspect Analysis\"):\n",
    "            row = {}\n",
    "\n",
    "            for aspect in self.aspects.keys():\n",
    "                data = self.analyze_aspect(text, aspect)\n",
    "\n",
    "                row[f\"{aspect}_mentioned\"] = bool(data[\"mentioned\"])\n",
    "                row[f\"{aspect}_sentiment\"] = data[\"sentiment\"]\n",
    "                row[f\"{aspect}_confidence\"] = float(data[\"confidence\"])\n",
    "\n",
    "            results.append(row)\n",
    "\n",
    "        return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# Run Aspect Analysis\n",
    "# ==============================\n",
    "\n",
    "aspect_analyzer = AspectAnalyzer(config, sentiment_engine)\n",
    "\n",
    "aspect_results = aspect_analyzer.batch_analyze(\n",
    "    df_cleaned[\"review_text\"].fillna(\"\").tolist()\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# Remove previous aspect columns (if re-run)\n",
    "# ------------------------------\n",
    "\n",
    "aspect_prefixes = list(config.aspects.keys())\n",
    "\n",
    "cols_to_drop = [\n",
    "    col for col in df_cleaned.columns\n",
    "    if any(col.startswith(prefix) for prefix in aspect_prefixes)\n",
    "]\n",
    "\n",
    "df_cleaned = df_cleaned.drop(columns=cols_to_drop, errors=\"ignore\")\n",
    "\n",
    "# ------------------------------\n",
    "# Safe Merge\n",
    "# ------------------------------\n",
    "\n",
    "df_cleaned = pd.concat(\n",
    "    [\n",
    "        df_cleaned.reset_index(drop=True),\n",
    "        aspect_results.reset_index(drop=True)\n",
    "    ],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# ==============================\n",
    "# Safe Aspect Summary\n",
    "# ==============================\n",
    "\n",
    "print(\"\\nüîç Aspect Analysis Summary:\")\n",
    "\n",
    "for aspect in config.aspects.keys():\n",
    "\n",
    "    col_mentioned = f\"{aspect}_mentioned\"\n",
    "    col_sentiment = f\"{aspect}_sentiment\"\n",
    "\n",
    "    if col_mentioned not in df_cleaned.columns:\n",
    "        continue\n",
    "\n",
    "    mask = df_cleaned[col_mentioned] == True\n",
    "    mentioned_count = int(mask.sum())\n",
    "\n",
    "    if mentioned_count > 0:\n",
    "\n",
    "        sentiment_dist = (\n",
    "            df_cleaned.loc[mask, col_sentiment]\n",
    "            .dropna()\n",
    "            .value_counts()\n",
    "        )\n",
    "\n",
    "        print(f\"\\n{aspect.upper()} ‚Üí {mentioned_count} mentions\")\n",
    "        print(sentiment_dist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è Conflict Detection - Multi-Level Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T16:01:36.239352Z",
     "iopub.status.busy": "2026-02-15T16:01:36.239022Z",
     "iopub.status.idle": "2026-02-15T16:01:36.276247Z",
     "shell.execute_reply": "2026-02-15T16:01:36.275533Z",
     "shell.execute_reply.started": "2026-02-15T16:01:36.239327Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö†Ô∏è Conflict Analysis:\n",
      "rating_sentiment_conflict\n",
      "No Conflict               799\n",
      "Ambiguous Experience       87\n",
      "Hidden Dissatisfaction     82\n",
      "Politeness Bias             9\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total Conflicts: 364 (37.3%)\n"
     ]
    }
   ],
   "source": [
    "class ConflictDetector:\n",
    "    \"\"\"Advanced conflict detection system\"\"\"\n",
    "    \n",
    "    def detect_rating_sentiment_conflict(self, row: pd.Series) -> str:\n",
    "        rating = row.get('review_rating', 0)\n",
    "        sentiment = row.get('overall_sentiment')\n",
    "        \n",
    "        if rating >= 4 and sentiment == 'negative':\n",
    "            return 'Hidden Dissatisfaction'\n",
    "        elif rating <= 2 and sentiment == 'positive':\n",
    "            return 'Politeness Bias'\n",
    "        elif rating == 3 and sentiment in ['positive', 'negative']:\n",
    "            return 'Ambiguous Experience'\n",
    "        else:\n",
    "            return 'No Conflict'\n",
    "    \n",
    "    def detect_aspect_conflicts(self, row: pd.Series, aspects: List[str]) -> int:\n",
    "        overall = row.get('overall_sentiment')\n",
    "        conflicts = 0\n",
    "        \n",
    "        for aspect in aspects:\n",
    "            if row.get(f'{aspect}_mentioned', False):\n",
    "                aspect_sent = row.get(f'{aspect}_sentiment')\n",
    "                if aspect_sent and aspect_sent != overall:\n",
    "                    conflicts += 1\n",
    "        \n",
    "        return conflicts\n",
    "    \n",
    "    def analyze(self, df: pd.DataFrame, aspects: List[str]) -> pd.DataFrame:\n",
    "        logger.info(\"Running conflict detection\")\n",
    "        \n",
    "        df['rating_sentiment_conflict'] = df.apply(\n",
    "            self.detect_rating_sentiment_conflict, axis=1\n",
    "        )\n",
    "        \n",
    "        df['aspect_conflict_count'] = df.apply(\n",
    "            lambda row: self.detect_aspect_conflicts(row, aspects), axis=1\n",
    "        )\n",
    "        \n",
    "        df['has_conflict'] = (\n",
    "            (df['rating_sentiment_conflict'] != 'No Conflict') |\n",
    "            (df['aspect_conflict_count'] > 0)\n",
    "        )\n",
    "        \n",
    "        logger.info(\"‚úÖ Conflict detection complete\")\n",
    "        return df\n",
    "\n",
    "conflict_detector = ConflictDetector()\n",
    "df_cleaned = conflict_detector.analyze(df_cleaned, list(config.aspects.keys()))\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è Conflict Analysis:\")\n",
    "print(df_cleaned['rating_sentiment_conflict'].value_counts())\n",
    "print(f\"\\nTotal Conflicts: {df_cleaned['has_conflict'].sum():,} ({df_cleaned['has_conflict'].mean():.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Chunking for RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T16:01:42.230224Z",
     "iopub.status.busy": "2026-02-15T16:01:42.229381Z",
     "iopub.status.idle": "2026-02-15T16:01:42.419411Z",
     "shell.execute_reply": "2026-02-15T16:01:42.418802Z",
     "shell.execute_reply.started": "2026-02-15T16:01:42.230177Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=400,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "def chunk_reviews(df):\n",
    "    new_rows = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        chunks = splitter.split_text(row[\"review_text\"])\n",
    "\n",
    "        for chunk in chunks:\n",
    "            new_row = row.copy()\n",
    "            new_row[\"review_text\"] = chunk\n",
    "            new_rows.append(new_row)\n",
    "\n",
    "    return pd.DataFrame(new_rows)\n",
    "\n",
    "df_chunked = chunk_reviews(df_cleaned)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üóÑÔ∏è Vector Database - RAG Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T16:01:48.999134Z",
     "iopub.status.busy": "2026-02-15T16:01:48.998454Z",
     "iopub.status.idle": "2026-02-15T16:01:53.921975Z",
     "shell.execute_reply": "2026-02-15T16:01:53.921149Z",
     "shell.execute_reply.started": "2026-02-15T16:01:48.999104Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e3b6d9972744352a472f9dbd37b81ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a31e89ebd3cc439b8b0fae458aa640f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5df32125e77448d95b19b803961d280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b3509f234af4b1096847c337342f0fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "294db8ec4efb4c67917b3d53ed24f10a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "118ed445e6f64e6c9275c8c4ccbb815c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da308ce21d3449fab3eb2b02dafcd5c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6c84ce7b9c7456a862e9ca301faa551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3311899af8ec48648fc1c7a7bf60b70f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db8dff4a5f9d4b839d349c00c9bb189a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17128a99ea4949d999eafeb9c9661a43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üóÑÔ∏è Vector Store Ready - 1,541 documents\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "class VectorStoreManager:\n",
    "    \"\"\"Production vector database manager\"\"\"\n",
    "    \n",
    "    def __init__(self, config: SystemConfig):\n",
    "        self.config = config\n",
    "        self.embeddings = None\n",
    "        self.vector_store = None\n",
    "        self._initialize_embeddings()\n",
    "    \n",
    "    def _initialize_embeddings(self):\n",
    "        try:\n",
    "            logger.info(f\"Loading embedding model: {self.config.embedding_model}\")\n",
    "            self.embeddings = HuggingFaceEmbeddings(\n",
    "                model_name=self.config.embedding_model\n",
    "            )\n",
    "            logger.info(\"‚úÖ Embedding model loaded\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Embedding model loading failed: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def create_documents(self, df: pd.DataFrame) -> List[Document]:\n",
    "        logger.info(f\"Creating {len(df)} documents\")\n",
    "        documents = []\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            aspect_summary = {}\n",
    "            for aspect in self.config.aspects.keys():\n",
    "                if row.get(f'{aspect}_mentioned', False):\n",
    "                    aspect_summary[aspect] = row.get(f'{aspect}_sentiment')\n",
    "            \n",
    "            doc = Document(\n",
    "                page_content=row['review_text'],\n",
    "                metadata={\n",
    "                    'restaurant': row['business_name'],\n",
    "                    'restaurant_normalized': row['business_name_normalized'],\n",
    "                    'rating': float(row['review_rating']),\n",
    "                    'sentiment': row['overall_sentiment'],\n",
    "                    'confidence': float(row['sentiment_confidence']),\n",
    "                    'aspects': json.dumps(aspect_summary),\n",
    "                    'conflict': row['rating_sentiment_conflict'],\n",
    "                    'has_conflict': bool(row['has_conflict'])\n",
    "                }\n",
    "            )\n",
    "            documents.append(doc)\n",
    "        \n",
    "        return documents\n",
    "    \n",
    "    def build_vector_store(self, documents: List[Document]) -> Chroma:\n",
    "        try:\n",
    "            if os.path.exists(self.config.vector_db_path):\n",
    "                shutil.rmtree(self.config.vector_db_path)\n",
    "            \n",
    "            logger.info(\"Building vector store...\")\n",
    "            self.vector_store = Chroma.from_documents(\n",
    "                documents=documents,\n",
    "                embedding=self.embeddings,\n",
    "                persist_directory=self.config.vector_db_path,\n",
    "                client_settings=Settings(anonymized_telemetry=False)\n",
    "            )\n",
    "            \n",
    "            logger.info(\"‚úÖ Vector store built\")\n",
    "            return self.vector_store\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Vector store creation failed: {e}\")\n",
    "            raise\n",
    "\n",
    "vector_manager = VectorStoreManager(config)\n",
    "documents = vector_manager.create_documents(df_chunked)\n",
    "vector_store = vector_manager.build_vector_store(documents)\n",
    "\n",
    "print(f\"\\nüóÑÔ∏è Vector Store Ready - {len(documents):,} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CELL 9: LLM Provider Layer ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T16:41:33.273557Z",
     "iopub.status.busy": "2026-02-15T16:41:33.272817Z",
     "iopub.status.idle": "2026-02-15T16:41:33.278456Z",
     "shell.execute_reply": "2026-02-15T16:41:33.277679Z",
     "shell.execute_reply.started": "2026-02-15T16:41:33.273525Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "# API key configure\n",
    "genai.configure(api_key=\"YOUR_API_KEY_HERE\")\n",
    "\n",
    "class GeminiLLM:\n",
    "    def __init__(self, temperature=0.0):\n",
    "        self.model = genai.GenerativeModel(\"models/gemini-2.5-flash\")\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def __call__(self, prompt: str):\n",
    "        response = self.model.generate_content(\n",
    "            prompt,\n",
    "            generation_config={\n",
    "                \"temperature\": 0.0,\n",
    "                \"top_p\": 0.8\n",
    "            }\n",
    "        )\n",
    "        return response.text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CELL 10: RAG Chatbot ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T16:41:37.431847Z",
     "iopub.status.busy": "2026-02-15T16:41:37.431296Z",
     "iopub.status.idle": "2026-02-15T16:41:37.445946Z",
     "shell.execute_reply": "2026-02-15T16:41:37.445182Z",
     "shell.execute_reply.started": "2026-02-15T16:41:37.431822Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "class RAGChatbot:\n",
    "\n",
    "    def __init__(self, vector_store, llm, config, df):\n",
    "        self.vector_store = vector_store\n",
    "        self.llm = llm\n",
    "        self.config = config\n",
    "        self.df = df\n",
    "        self.memory = []\n",
    "        self.recommendation_engine = RecommendationEngine(df)\n",
    "\n",
    "    # ---------------------------\n",
    "    # Intent Detection\n",
    "    # ---------------------------\n",
    "    def classify_query(self, question):\n",
    "        q = question.lower()\n",
    "\n",
    "        if re.search(r\"top\\s*\\d+\", q):\n",
    "            return \"top_n\"\n",
    "\n",
    "        if \"compare\" in q:\n",
    "            return \"comparison\"\n",
    "\n",
    "        if \"best\" in q or \"rank\" in q:\n",
    "            return \"ranking\"\n",
    "\n",
    "        if \"recommend\" in q:\n",
    "            return \"recommendation\"\n",
    "\n",
    "        return \"general\"\n",
    "\n",
    "    # ---------------------------\n",
    "    # Extract Top N\n",
    "    # ---------------------------\n",
    "    def extract_top_n(self, question):\n",
    "        match = re.search(r\"top\\s*(\\d+)\", question.lower())\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "        return None\n",
    "\n",
    "    # ---------------------------\n",
    "    # Extract Restaurant Entities\n",
    "    # ---------------------------\n",
    "    def extract_entities(self, question):\n",
    "        q = question.lower()\n",
    "        entities = []\n",
    "\n",
    "        for name in self.df[\"business_name_normalized\"].unique():\n",
    "            if name in q:\n",
    "                entities.append(name)\n",
    "\n",
    "        return entities\n",
    "\n",
    "    # ---------------------------\n",
    "    # Dataset-wide Ranking\n",
    "    # ---------------------------\n",
    "    def rank_restaurants(self, top_n=5, focus=\"overall\"):\n",
    "\n",
    "        results = []\n",
    "\n",
    "        for r in self.df[\"business_name_normalized\"].unique():\n",
    "            score_data = self.recommendation_engine.calculate_score(r)\n",
    "\n",
    "            if \"error\" not in score_data:\n",
    "                results.append(score_data)\n",
    "\n",
    "        ranked = sorted(results, key=lambda x: x[\"total_score\"], reverse=True)\n",
    "\n",
    "        return ranked[:top_n]\n",
    "\n",
    "    # ---------------------------\n",
    "    # Multi-Restaurant Comparison\n",
    "    # ---------------------------\n",
    "    def compare_restaurants(self, entities):\n",
    "\n",
    "        comparisons = []\n",
    "\n",
    "        for e in entities:\n",
    "            score_data = self.recommendation_engine.calculate_score(e)\n",
    "            if \"error\" not in score_data:\n",
    "                comparisons.append(score_data)\n",
    "\n",
    "        if len(comparisons) < 2:\n",
    "            return None\n",
    "\n",
    "        ranked = sorted(comparisons, key=lambda x: x[\"total_score\"], reverse=True)\n",
    "\n",
    "        return ranked\n",
    "\n",
    "    # ---------------------------\n",
    "    # Human-Friendly Presentation Layer\n",
    "    # ---------------------------\n",
    "    def present_ranking(self, ranked_list):\n",
    "\n",
    "        text = \"Here are the strongest performers based on your dataset:\\n\\n\"\n",
    "\n",
    "        for i, r in enumerate(ranked_list, 1):\n",
    "            text += f\"{i}. {r['restaurant']} (Score: {r['total_score']})\\n\"\n",
    "\n",
    "        text += \"\\nThese rankings are calculated using sentiment strength, rating consistency, volume, and confidence.\"\n",
    "\n",
    "        return text\n",
    "\n",
    "    def present_comparison(self, ranked_list):\n",
    "\n",
    "        text = \"Here‚Äôs a clear comparison based on your dataset:\\n\\n\"\n",
    "\n",
    "        for r in ranked_list:\n",
    "            text += (\n",
    "                f\"{r['restaurant']} ‚Üí \"\n",
    "                f\"Score: {r['total_score']}, \"\n",
    "                f\"Avg Rating: {r['average_rating']}, \"\n",
    "                f\"Reviews: {r['review_count']}\\n\"\n",
    "            )\n",
    "\n",
    "        winner = ranked_list[0][\"restaurant\"]\n",
    "\n",
    "        text += f\"\\nOverall, {winner} currently shows the strongest performance based on available data.\"\n",
    "\n",
    "        return text\n",
    "\n",
    "    # ---------------------------\n",
    "    # General RAG Mode\n",
    "    # ---------------------------\n",
    "    def rag_answer(self, question):\n",
    "\n",
    "        docs = self.vector_store.similarity_search(question, k=self.config.retrieval_k)\n",
    "\n",
    "        if not docs:\n",
    "            return {\n",
    "                \"answer\": \"I don‚Äôt see enough relevant review evidence for that specific question.\",\n",
    "                \"confidence\": 0.0\n",
    "            }\n",
    "\n",
    "        context = \"\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "You are a restaurant analytics consultant.\n",
    "\n",
    "Answer naturally and clearly.\n",
    "Avoid academic tone.\n",
    "Use only provided evidence.\n",
    "\n",
    "Evidence:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "        answer = self.llm(prompt)\n",
    "\n",
    "        return {\n",
    "            \"answer\": answer,\n",
    "            \"confidence\": 0.85\n",
    "        }\n",
    "\n",
    "    # ---------------------------\n",
    "    # Main Query Router\n",
    "    # ---------------------------\n",
    "    def query(self, question, restaurant_filter=None):\n",
    "\n",
    "        intent = self.classify_query(question)\n",
    "\n",
    "        # -------- Top N Mode --------\n",
    "        if intent == \"top_n\":\n",
    "            top_n = self.extract_top_n(question) or 5\n",
    "            ranked = self.rank_restaurants(top_n)\n",
    "            answer = self.present_ranking(ranked)\n",
    "\n",
    "            return {\n",
    "                \"answer\": answer,\n",
    "                \"confidence\": 0.95,\n",
    "                \"intent\": intent\n",
    "            }\n",
    "\n",
    "        # -------- Comparison Mode --------\n",
    "        entities = self.extract_entities(question)\n",
    "\n",
    "        if intent == \"comparison\" and len(entities) >= 2:\n",
    "            ranked = self.compare_restaurants(entities)\n",
    "\n",
    "            if ranked:\n",
    "                answer = self.present_comparison(ranked)\n",
    "\n",
    "                return {\n",
    "                    \"answer\": answer,\n",
    "                    \"confidence\": 0.93,\n",
    "                    \"intent\": intent\n",
    "                }\n",
    "\n",
    "        # -------- General RAG Mode --------\n",
    "        rag_response = self.rag_answer(question)\n",
    "        rag_response[\"intent\"] = \"general\"\n",
    "\n",
    "        return rag_response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CELL 11: Recommendation Engine ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T16:41:44.195798Z",
     "iopub.status.busy": "2026-02-15T16:41:44.195479Z",
     "iopub.status.idle": "2026-02-15T16:41:44.203640Z",
     "shell.execute_reply": "2026-02-15T16:41:44.203039Z",
     "shell.execute_reply.started": "2026-02-15T16:41:44.195752Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class RecommendationEngine:\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df\n",
    "\n",
    "    def calculate_score(self, restaurant_name: str):\n",
    "\n",
    "        df_rest = self.df[\n",
    "            self.df[\"business_name_normalized\"] == restaurant_name.lower()\n",
    "        ]\n",
    "\n",
    "        if df_rest.empty:\n",
    "            return {\"error\": \"Restaurant not found\"}\n",
    "\n",
    "        if len(df_rest) < 5:\n",
    "            return {\"error\": \"Not enough review volume for reliable ranking\"}\n",
    "\n",
    "        # =============================\n",
    "        # Sentiment Score (40%)\n",
    "        # =============================\n",
    "        sentiment_score = (df_rest[\"overall_sentiment\"] == \"positive\").mean() * 40\n",
    "\n",
    "        # =============================\n",
    "        # Aspect Score (25%)\n",
    "        # =============================\n",
    "        aspect_cols = [c for c in df_rest.columns if \"_sentiment\" in c]\n",
    "\n",
    "        aspect_score_total = 0\n",
    "        aspect_count = 0\n",
    "\n",
    "        for col in aspect_cols:\n",
    "            mentioned = df_rest[df_rest[col.replace(\"_sentiment\",\"_mentioned\")] == True]\n",
    "            if not mentioned.empty:\n",
    "                pos_rate = (mentioned[col] == \"positive\").mean()\n",
    "                aspect_score_total += pos_rate\n",
    "                aspect_count += 1\n",
    "\n",
    "        aspect_score = (aspect_score_total / aspect_count) * 25 if aspect_count > 0 else 0\n",
    "\n",
    "        # =============================\n",
    "        # Conflict Penalty (15%)\n",
    "        # =============================\n",
    "        conflict_rate = df_rest[\"has_conflict\"].mean()\n",
    "        conflict_score = (1 - conflict_rate) * 15\n",
    "\n",
    "        # =============================\n",
    "        # Volume Bonus (10%)\n",
    "        # =============================\n",
    "        volume_score = min(len(df_rest) / 100, 1.0) * 10\n",
    "\n",
    "        # =============================\n",
    "        # Confidence Bonus (10%)\n",
    "        # =============================\n",
    "        confidence_score = df_rest[\"sentiment_confidence\"].mean() * 10\n",
    "\n",
    "        total_score = (\n",
    "            sentiment_score +\n",
    "            aspect_score +\n",
    "            conflict_score +\n",
    "            volume_score +\n",
    "            confidence_score\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"restaurant\": restaurant_name,\n",
    "            \"total_score\": round(total_score, 2),\n",
    "            \"review_volume\": len(df_rest),\n",
    "            \"sentiment_positive_ratio\": round((df_rest[\"overall_sentiment\"] == \"positive\").mean(), 2),\n",
    "            \"conflict_rate\": round(conflict_rate, 2)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T16:41:51.083410Z",
     "iopub.status.busy": "2026-02-15T16:41:51.083043Z",
     "iopub.status.idle": "2026-02-15T16:41:51.087139Z",
     "shell.execute_reply": "2026-02-15T16:41:51.086467Z",
     "shell.execute_reply.started": "2026-02-15T16:41:51.083384Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "llm = GeminiLLM()\n",
    "chatbot = RAGChatbot(vector_store, llm, config, df_cleaned)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T16:02:19.016143Z",
     "iopub.status.busy": "2026-02-15T16:02:19.015647Z",
     "iopub.status.idle": "2026-02-15T16:02:19.021014Z",
     "shell.execute_reply": "2026-02-15T16:02:19.020194Z",
     "shell.execute_reply.started": "2026-02-15T16:02:19.016116Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Chatbot auto-initialized successfully\n"
     ]
    }
   ],
   "source": [
    "# --- Ensure Chatbot Initialized ---\n",
    "\n",
    "if \"vector_store\" not in globals():\n",
    "    raise RuntimeError(\"‚ùå Vector store not found. Run vector store build cell first.\")\n",
    "\n",
    "if \"llm\" not in globals():\n",
    "    llm = GeminiLLM()\n",
    "\n",
    "if \"chatbot\" not in globals():\n",
    "    if \"df_cleaned\" in globals():\n",
    "        chatbot = RAGChatbot(vector_store, llm, config, df_cleaned)\n",
    "    elif \"df_chunked\" in globals():\n",
    "        chatbot = RAGChatbot(vector_store, llm, config, df_chunked)\n",
    "    else:\n",
    "        raise RuntimeError(\"‚ùå No dataframe found for chatbot initialization.\")\n",
    "    \n",
    "    print(\"‚úÖ Chatbot auto-initialized successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CELL 12: Interactive Chat Interface ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T16:41:55.867302Z",
     "iopub.status.busy": "2026-02-15T16:41:55.866708Z",
     "iopub.status.idle": "2026-02-15T16:41:55.891656Z",
     "shell.execute_reply": "2026-02-15T16:41:55.890765Z",
     "shell.execute_reply.started": "2026-02-15T16:41:55.867276Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ü§ñ INTERACTIVE RESTAURANT CHATBOT\n",
      "================================================================================\n",
      "\n",
      "Ask questions about restaurants or get recommendations!\n",
      "\n",
      "Example questions:\n",
      "  - Which restaurant has the best food?\n",
      "  - Tell me about the service quality\n",
      "  - Is Izumi Japanese Kitchen good for couples?\n",
      "  - What do people say about prices?\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5be9a09f41ed4d9a98ff105a023d300f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>üçΩÔ∏è Restaurant Intelligence Chatbot</h3>'), Text(value='', description='Question‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML, clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Chat history\n",
    "chat_history = []\n",
    "\n",
    "# Create UI components\n",
    "output_area = widgets.Output()\n",
    "question_input = widgets.Text(\n",
    "    placeholder='Ask about restaurants (e.g., \"Best food quality?\")',\n",
    "    description='Question:',\n",
    "    layout=widgets.Layout(width='70%')\n",
    ")\n",
    "restaurant_input = widgets.Text(\n",
    "    placeholder='Optional: Filter by restaurant name',\n",
    "    description='Restaurant:',\n",
    "    layout=widgets.Layout(width='70%')\n",
    ")\n",
    "send_button = widgets.Button(\n",
    "    description='Send',\n",
    "    button_style='primary',\n",
    "    icon='paper-plane'\n",
    ")\n",
    "clear_button = widgets.Button(\n",
    "    description='Clear Chat',\n",
    "    button_style='warning',\n",
    "    icon='trash'\n",
    ")\n",
    "\n",
    "def format_chat_message(role, message, sources=None):\n",
    "    \"\"\"Format chat message with styling\"\"\"\n",
    "    if role == \"user\":\n",
    "        return f'''\n",
    "        <div style=\"background: #e3f2fd; padding: 10px; margin: 5px 0; border-radius: 10px; border-left: 4px solid #2196F3;\">\n",
    "            <strong>üßë You:</strong> {message}\n",
    "        </div>\n",
    "        '''\n",
    "    else:\n",
    "        return f\"\"\"\n",
    "        <div style='background: #f5f5f5; padding: 10px; margin: 5px; border-radius: 10px; border-left: 4px solid #6C63FF;'>\n",
    "            <strong>ü§ñ Assistant:</strong><br>\n",
    "            {message}\n",
    "        </div>\n",
    "        \"\"\"\n",
    "\n",
    "def send_message(b):\n",
    "    \"\"\"Handle send button click\"\"\"\n",
    "    question = question_input.value.strip()\n",
    "    restaurant = restaurant_input.value.strip() if restaurant_input.value.strip() else None\n",
    "\n",
    "    if not question:\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            for msg in chat_history:\n",
    "                display(HTML(msg))\n",
    "            display(HTML('<p style=\"color: red;\">‚ö†Ô∏è Please enter a qquestion</p>'))\n",
    "        return\n",
    "\n",
    "    # Add user message to history\n",
    "    user_msg = format_chat_message(\"user\", question + (f\" (Restaurant: {restaurant})\" if restaurant else \"\"))\n",
    "    chat_history.append(user_msg)\n",
    "\n",
    "    # Get response\n",
    "    result = chatbot.query(question, restaurant_filter=restaurant)  \n",
    "\n",
    "    # Add bot response to history\n",
    "    bot_msg = format_chat_message(\n",
    "        \"assistant\",\n",
    "        result[\"answer\"] + f\"\\n\\nConfidence: {result['confidence']}\"\n",
    "    )\n",
    "\n",
    "    chat_history.append(bot_msg)\n",
    "\n",
    "    # Update display\n",
    "    with output_area:\n",
    "        clear_output(wait=True)\n",
    "        for msg in chat_history:\n",
    "            display(HTML(msg))\n",
    "\n",
    "    # Clear inputs\n",
    "    question_input.value = \"\"\n",
    "    restaurant_input.value = \"\"\n",
    "\n",
    "def clear_chat(b):\n",
    "    \"\"\"Clear chat history\"\"\"\n",
    "    global chat_history\n",
    "    chat_history = []\n",
    "    with output_area:\n",
    "        clear_output()\n",
    "        display(HTML('<p style=\"color: #666;\">Chat cleared. Start a new conversation!</p>'))\n",
    "\n",
    "# Attach event handlers\n",
    "send_button.on_click(send_message)\n",
    "clear_button.on_click(clear_chat)\n",
    "question_input.on_submit(lambda x: send_message(None))\n",
    "\n",
    "# Display UI\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ü§ñ INTERACTIVE RESTAURANT CHATBOT\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nAsk questions about restaurants or get recommendations!\")  \n",
    "print(\"\\nExample questions:\")\n",
    "print(\"  - Which restaurant has the best food?\")\n",
    "print(\"  - Tell me about the service quality\")\n",
    "print(\"  - Is Izumi Japanese Kitchen good for couples?\")\n",
    "print(\"  - What do people say about prices?\")\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h3>üçΩÔ∏è Restaurant Intelligence Chatbot</h3>\"),    \n",
    "    question_input,\n",
    "    restaurant_input,\n",
    "    widgets.HBox([send_button, clear_button]),\n",
    "    output_area\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "docs = vector_store.similarity_search(\"KFC\", k=3)\n",
    "\n",
    "for d in docs:\n",
    "    print(d.metadata)\n",
    "    print(\"------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "entities = chatbot.extract_entities(\"Tell me about Pallabi Hotel & Restaurant\")\n",
    "\n",
    "docs = chatbot.hybrid_retrieval(\n",
    "    \"Tell me about Pallabi Hotel & Restaurant\",\n",
    "    entities,\n",
    "    k=6\n",
    ")\n",
    "\n",
    "print(\"Total docs:\", len(docs))\n",
    "\n",
    "for d in docs:\n",
    "    print(d.metadata[\"restaurant\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # # Data Export for FastAPI  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Create data directory\n",
    "data_dir = \"data\"\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# Export processed DataFrame to CSV\n",
    "output_path = os.path.join(data_dir, \"processed_reviews.csv\")\n",
    "df_cleaned.to_csv(output_path, index=False)\n",
    "print(f\"‚úÖ Exported {len(df_cleaned)} reviews to {output_path}\")\n",
    "\n",
    "# Export as pickle (faster loading)\n",
    "pickle_path = os.path.join(data_dir, \"processed_reviews.pkl\")\n",
    "df_cleaned.to_pickle(pickle_path)\n",
    "print(f\"‚úÖ Exported pickle to {pickle_path}\")\n",
    "\n",
    "# Copy vector database\n",
    "source_vector_db = \"/kaggle/working/restaurant_vector_db\"\n",
    "target_vector_db = \"restaurant_vector_db\"\n",
    "\n",
    "if os.path.exists(source_vector_db):\n",
    "    if os.path.exists(target_vector_db):\n",
    "        shutil.rmtree(target_vector_db)\n",
    "    shutil.copytree(source_vector_db, target_vector_db)\n",
    "    print(f\"‚úÖ Copied vector database to {target_vector_db}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Vector database not found\")\n",
    "\n",
    "print(\"\\nüéâ Data export complete!\")\n",
    "print(\"\\nFiles created:\")\n",
    "print(\"  - data/processed_reviews.csv\")\n",
    "print(\"  - data/processed_reviews.pkl\")\n",
    "print(\"  - restaurant_vector_db/ (folder)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from langchain.vectorstores import Chroma\n",
    "from chromadb.config import Settings\n",
    "\n",
    "# Target Path\n",
    "VECT_DB_PATH = \"/kaggle/working/restaurant_vector_db\"\n",
    "\n",
    "print(f\"üéØ Force building at: {VECT_DB_PATH}\")\n",
    "\n",
    "# 1. Clean up\n",
    "if os.path.exists(VECT_DB_PATH):\n",
    "    shutil.rmtree(VECT_DB_PATH)\n",
    "\n",
    "# 2. Get documents and embeddings manually\n",
    "print(\"üìÑ Preparing documents...\")\n",
    "vector_manager = VectorStoreManager(config)\n",
    "documents = vector_manager.create_documents(df_chunked)\n",
    "embeddings = vector_manager.embeddings\n",
    "\n",
    "# 3. Direct Chroma Creation (Bypassing Manager)\n",
    "print(\"üèóÔ∏è Creating ChromaDB directly...\")\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=VECT_DB_PATH,\n",
    "    client_settings=Settings(anonymized_telemetry=False)\n",
    ")\n",
    "\n",
    "# 4. Force Persist (IMPORTANT for older Chroma versions)\n",
    "try:\n",
    "    vector_store.persist()\n",
    "    print(\"üíæ Forced persistence called.\")\n",
    "except:\n",
    "    print(\"‚ÑπÔ∏è Auto-persistence enabled (newer Chroma version).\")\n",
    "\n",
    "# 5. Verify & Zip\n",
    "if os.path.exists(VECT_DB_PATH):\n",
    "    print(f\"‚úÖ SUCCESS! Folder created: {os.listdir(VECT_DB_PATH)}\")\n",
    "    shutil.make_archive(\"restaurant_vector_db\", 'zip', root_dir=\"/kaggle/working\", base_dir=\"restaurant_vector_db\")\n",
    "    print(\"üéâ 'restaurant_vector_db.zip' is ready to download!\")\n",
    "else:\n",
    "    print(\"‚ùå STILL FAILED. ChromaDB is refusing to write to this path.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 9461926,
     "sourceId": 14798432,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9484740,
     "sourceId": 14830169,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
